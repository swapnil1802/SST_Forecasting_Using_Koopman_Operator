{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"Dataset/\"\n",
    "\n",
    "processed_data = {}\n",
    "\n",
    "#Calculate global minimum and maximum SST values across all years\n",
    "global_min_sst = float('inf')\n",
    "global_max_sst = float('-inf')\n",
    "\n",
    "for year in range(1981, 2024 + 1):\n",
    "    year_str = str(year)\n",
    "    file_path = os.path.join(data_dir, f'sst.day.mean.{year}.nc') \n",
    "\n",
    "    try:\n",
    "        # Loading the dataset\n",
    "        dataset = xr.open_dataset(file_path)\n",
    "\n",
    "        # Subset the dataset for the smaller region of interest\n",
    "        region_sst = dataset['sst'].where(\n",
    "            (dataset['lat'] >= -2) & (dataset['lat'] <= 2) &  \n",
    "            (dataset['lon'] >= 234) & (dataset['lon'] <= 240), \n",
    "            drop=True  # Drop points outside this range\n",
    "        )\n",
    "\n",
    "        \n",
    "        year_min = region_sst.min().values\n",
    "        year_max = region_sst.max().values\n",
    "        global_min_sst = min(global_min_sst, year_min)\n",
    "        global_max_sst = max(global_max_sst, year_max)\n",
    "\n",
    "        print(f\"Checked year {year} for global min and max.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for {year} not found. Skipping this year.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {year}: {e}\")\n",
    "\n",
    "print(f\"Global Min SST: {global_min_sst}, Global Max SST: {global_max_sst}\")\n",
    "\n",
    "# Process and scale SST data for each year using global min and max\n",
    "for year in range(1982, 2024 + 1):\n",
    "    year_str = str(year)\n",
    "    file_path = os.path.join(data_dir, f'sst.day.mean.{year}.nc')\n",
    "\n",
    "    try:\n",
    "        \n",
    "        dataset = xr.open_dataset(file_path)\n",
    "\n",
    "        \n",
    "        region_sst = dataset['sst'].where(\n",
    "            (dataset['lat'] >= -2) & (dataset['lat'] <= 2) &  \n",
    "            (dataset['lon'] >= 234) & (dataset['lon'] <= 240), \n",
    "            drop=True  \n",
    "        )\n",
    "        \n",
    "        region_sst_scaled = (2 * (region_sst - global_min_sst) / (global_max_sst - global_min_sst)) - 1\n",
    "\n",
    "        # Store the processed data in the dictionary with year as key\n",
    "        processed_data[year_str] = region_sst_scaled\n",
    "        print(f\"Processed year {year}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for {year} not found. Skipping this year.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {year}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_years = list(range(2015, 2025))\n",
    "test_data = np.concatenate([processed_data[str(year)] for year in test_years], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_model_n_days_iterative(test_data, seq_length, n_days):\n",
    "    total_days = test_data.shape[0]\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    for t in range(seq_length, total_days - n_days + 1):\n",
    "        # Initialize the input window using ground truth\n",
    "        input_window = test_data[t - seq_length:t].copy()\n",
    "        future_preds = []\n",
    "        targets.append(test_data[t:t + n_days])  # Collect ground truth for the same range\n",
    "\n",
    "        for day in range(n_days):\n",
    "            # Compute the average over the input window\n",
    "            avg_prediction = np.mean(input_window, axis=0)  \n",
    "\n",
    "            future_preds.append(avg_prediction)\n",
    "\n",
    "            # Update the input window: shift by removing the oldest value and appending the predicted day\n",
    "            input_window = np.concatenate([input_window[1:], avg_prediction[np.newaxis, :, :]], axis=0)\n",
    "\n",
    "        predictions.append(np.stack(future_preds, axis=0))  \n",
    "\n",
    "    predictions = np.array(predictions)  \n",
    "    targets = np.array(targets)  \n",
    "    return predictions, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, targets):\n",
    "    \"\"\"\n",
    "    Compute MAE, RMSE, and R² between predictions and targets.\n",
    "\n",
    "    Args:\n",
    "        predictions: Predicted SST values, shape\n",
    "        targets: Ground truth SST values, shape \n",
    "\n",
    "    Returns:\n",
    "        mae: Mean Absolute Error.\n",
    "        rmse: Root Mean Square Error.\n",
    "        r2: Coefficient of Determination (R²).\n",
    "    \"\"\"\n",
    "    mae = np.mean(np.abs(predictions - targets))  # Mean Absolute Error\n",
    "    mse = np.mean((predictions - targets) ** 2)  # Mean Squared Error\n",
    "    rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "\n",
    "    # Compute R²\n",
    "    ss_total = np.sum((targets - targets.mean()) ** 2)  # Total sum of squares\n",
    "    ss_residual = np.sum((targets - predictions) ** 2)  # Residual sum of squares\n",
    "    r2 = 1 - (ss_residual / ss_total) if ss_total > 0 else 0\n",
    "\n",
    "    return mae, rmse, r2\n",
    "\n",
    "\n",
    "def inverse_scale(data, global_min_sst, global_max_sst):\n",
    "    return ((data + 1) / 2) * (global_max_sst - global_min_sst) + global_min_sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Metrics\n",
    "seq_length = 30  # Input window size\n",
    "n_days = 30\n",
    "\n",
    "average_predictions, average_targets = average_model_n_days_iterative(test_data, seq_length, n_days)\n",
    "\n",
    "# Rescale Predictions and Ground Truth\n",
    "average_predictions_rescaled = inverse_scale(average_predictions, global_min_sst, global_max_sst)\n",
    "ground_truth_rescaled = inverse_scale(average_targets, global_min_sst, global_max_sst)\n",
    "mae, rmse, r2 = compute_metrics(average_predictions_rescaled, ground_truth_rescaled)\n",
    "\n",
    "print(f\"Average Model - MAE: {mae:.4f} °C\")\n",
    "print(f\"Average Model - RMSE: {rmse:.4f} °C\")\n",
    "print(f\"Average Model - R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap Plotting Function\n",
    "def plot_heatmap_baseline(data, title, day_index, global_min_sst, global_max_sst):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(data, cmap='coolwarm', vmin=global_min_sst, vmax=global_max_sst)\n",
    "    plt.colorbar(label=\"Sea Surface Temperature (°C)\")\n",
    "    plt.title(f\"{title} (Day {day_index + 30})\", fontsize=14)\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_length = 30\n",
    "n_days = 30  # Predict 30 days into the future\n",
    "day_to_plot = 31 # The specific day for heatmap plotting\n",
    "\n",
    "\n",
    "aligned_day_index = day_to_plot - seq_length\n",
    "if aligned_day_index < 0 or aligned_day_index >= test_data.shape[0] - n_days + 1:\n",
    "    print(f\"Invalid day_to_plot: {day_to_plot}\")\n",
    "else:\n",
    "    # Average Model Predictions\n",
    "    avg_predictions, avg_targets = average_model_n_days_iterative(test_data, seq_length, n_days)\n",
    "    avg_predictions_rescaled = inverse_scale(avg_predictions, global_min_sst, global_max_sst)\n",
    "    avg_targets_rescaled = inverse_scale(avg_targets, global_min_sst, global_max_sst)\n",
    "\n",
    "\n",
    "    # Extract corresponding ground truth and predictions for the specified day\n",
    "    avg_prediction_heatmap = avg_predictions_rescaled[aligned_day_index, -1]  # Last day prediction\n",
    "    ground_truth_heatmap = avg_targets_rescaled[aligned_day_index, -1]  \n",
    "\n",
    "    # Plot Heatmaps\n",
    "    plot_heatmap_baseline(ground_truth_heatmap, f\"Ground Truth SST\", day_to_plot, global_min_sst, global_max_sst)\n",
    "    plot_heatmap_baseline(avg_prediction_heatmap, f\"Average Model Prediction\", day_to_plot, global_min_sst, global_max_sst)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
